{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: Text Compression"
      ],
      "metadata": {
        "id": "GwkU0W2IETgs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rr7tlzi8Eoc5"
      },
      "outputs": [],
      "source": [
        "# Goal\n",
        "# Create a dictionary and list that contains the entirety of\n",
        "# Harry Potter Book 1 and:\n",
        "# 1) (Optional) Takes less space than the original txt document\n",
        "# 2) Can be reprocessed into an exact copy of the original document"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read all lines\n",
        "hpReader = open(\"HP1.txt\", \"r+\")\n",
        "hpList = hpReader.readlines()"
      ],
      "metadata": {
        "id": "291O1xzJFPZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# update rows so that \\n is replaced by &\n",
        "hpListupdate = [s.replace(\"\\n\",\"&\").replace(\".\",\" . \").replace(\",\",\" , \").replace(\";\",\" ; \").replace(\"!\",\" ! \")for s in hpList]\n",
        "hpListupdate[0].lower().split()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ASfowJkNVQF",
        "outputId": "0671dadb-c611-45c8-a295-5a7f37529de2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['harry', 'potter', 'and', 'the', \"sorcerer's\", 'stone&']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# processing lines into dictionary\n",
        "\"\"\"\n",
        "def processLines(bookLines, caseSensitive = False):\n",
        "  #print(bookLines)\n",
        "  wordDict = {}\n",
        "  # each sentence\n",
        "  for line in bookLines:\n",
        "    #print(line)\n",
        "    # each word\n",
        "    if caseSensitive:\n",
        "      for word in line.split():\n",
        "        #print(word)\n",
        "        if word in wordDict:\n",
        "          wordDict[word] += 1\n",
        "        else:\n",
        "          print(word)\n",
        "          wordDict[word] = 1\n",
        "    else:\n",
        "      for word in line.lower().split():\n",
        "        #print(word)\n",
        "        if word in wordDict:\n",
        "          wordDict[word] += 1\n",
        "        else:\n",
        "          print(word)\n",
        "          wordDict[word] = 1\n",
        "  return wordDict\n",
        "  \"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "aBrvPGA3FdzN",
        "outputId": "c3e45c5f-bb48-4d53-e1bb-038e6a66b59b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef processLines(bookLines, caseSensitive = False):\\n  #print(bookLines)\\n  wordDict = {}\\n  # each sentence\\n  for line in bookLines:\\n    #print(line)\\n    # each word\\n    if caseSensitive:\\n      for word in line.split():\\n        #print(word)\\n        if word in wordDict:\\n          wordDict[word] += 1\\n        else:\\n          print(word)\\n          wordDict[word] = 1\\n    else:\\n      for word in line.lower().split():\\n        #print(word)\\n        if word in wordDict:\\n          wordDict[word] += 1\\n        else:\\n          print(word)\\n          wordDict[word] = 1\\n  return wordDict\\n  '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# processing lines into list of words\n",
        "def processLinesToWords(bookLines, caseSensitive = False):\n",
        "  #print(bookLines)\n",
        "  wordList = []\n",
        "  placeList = []\n",
        "  # each sentence\n",
        "  for line in bookLines:\n",
        "    #print(line)\n",
        "    # each word\n",
        "    for word in line.split():\n",
        "      if not caseSensitive:\n",
        "        word = word.lower()\n",
        "      if word not in wordList:\n",
        "        wordList.append(word)\n",
        "      placeList.append(wordList.index(word))\n",
        "  return (wordList,placeList)"
      ],
      "metadata": {
        "id": "uydSDtKs7vUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# processing list to dictionary\n",
        "def processWordsToDict(bookList):\n",
        "  wordDict = {}\n",
        "  for word in bookList:\n",
        "    if word in wordDict:\n",
        "      wordDict[word] += 1\n",
        "    else:\n",
        "      wordDict[word] = 1\n",
        "  return wordDict"
      ],
      "metadata": {
        "id": "Y4UBX1x8YR2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def processLinesToDict(bookLines):\n",
        "  result = processLinesToWords(bookLines)\n",
        "  result = processWordsToDict(result)\n",
        "  return result"
      ],
      "metadata": {
        "id": "Lj4NzSt3ueJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = processLinesToWords(hpListupdate)\n",
        "print(len(result[1]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmhMkhKIFoFF",
        "outputId": "48a8cd55-98f7-4159-f5e9-93e0a75add33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "97781\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"There are:\",len(result[0]),\"unique words\")\n",
        "print(\"There are:\",len(result[1]),\"words\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZxCCY8P2139",
        "outputId": "ac9ea7d1-b417-4c4c-bb58-231e6691b9b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are: 8325 unique words\n",
            "There are: 97781 words\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result[0][1000:1005])\n",
        "print(result[1][1000:1005])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0epm4Rzg3NiT",
        "outputId": "78c6bc01-bc0a-4369-f126-1391d7b6fd57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['confusing', 'we', 'keep', \"'you-know-who\", \"'\"]\n",
            "[402, 54, 403, 404, 13]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "print(sys.getsizeof(result))\n",
        "print(sys.getsizeof(hpList))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAHSdntSBqFV",
        "outputId": "2b77af70-66f9-4c34-9941-d0272cfdabd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "56\n",
            "95864\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "def createFile(result):\n",
        "  #hpReader = open(\"HP1-created.txt\", \"w+\")\n",
        "\n",
        "  with open('sample_data/university_records.csv', 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerows(result[1])\n"
      ],
      "metadata": {
        "id": "rcCZ8bFKGQyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def revert(resultWords, resultPlacement):\n",
        "  overallList = []"
      ],
      "metadata": {
        "id": "xuzDNh-su4cb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Uqkgz5qgu404"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: Unique Word String"
      ],
      "metadata": {
        "id": "08hiAmTNEZ3G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9KEWuwRPjL2"
      },
      "outputs": [],
      "source": [
        "# Goal\n",
        "# Create a single string of characters that is able to contain every word in\n",
        "# harry potter book 1 in order.\n",
        "# For the sake of discussion this result will be called a UniqueWordString"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# /[w+]-[w+]/"
      ],
      "metadata": {
        "id": "MUFx-MRZVA2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example\n",
        "# Input: hello, we, treat, eat, low\n",
        "# Processing: hello\n",
        "#             hello + we\n",
        "#             hellowe + treat\n",
        "#             hel[low]etreat stays the same\n",
        "#             hellowetr[eat] stays the same\n",
        "# Output: hellowetreat"
      ],
      "metadata": {
        "id": "MeG851uiP1dR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Steps:\n",
        "# -  Import data\n",
        "# -  Read all lines\n",
        "# -  Process all lines into individual words\n",
        "# -  (optional) Trim all grammar\n",
        "# -  (optional) Remove chapter number and titles (lines with only all caps)\n",
        "# -  (optional) Convert all remaining text to lower case\n",
        "# -  Get all unique words (in order of appearance)\n",
        "# -  Process all words into the UniqueWordString"
      ],
      "metadata": {
        "id": "hTeDf_FzQsW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read all lines\n",
        "hpReader = open(\"HP1.txt\", \"r+\")\n",
        "hpList = hpReader.readlines()"
      ],
      "metadata": {
        "id": "BquSZChpXW75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trailing newlines (\\n)\n",
        "print(len(hpList))\n",
        "print(hpList[0])\n",
        "print(hpList[10])\n",
        "print(hpList[0], end=\"\")\n",
        "print(hpList[10], end=\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpZGdu4FYus_",
        "outputId": "06881899-e68f-4eec-cce1-69df91408e2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10702\n",
            "Harry Potter and the Sorcerer's Stone\n",
            "\n",
            "because they just didn't hold with such nonsense.\n",
            "\n",
            "Harry Potter and the Sorcerer's Stone\n",
            "because they just didn't hold with such nonsense.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning the data\n",
        "hpListTrim = [s.translate(str.maketrans({\"!\":\"\", \"\\\"\":\"\", \"\\'\":\"\", \".\":\"\",\n",
        "                                         \";\":\"\", \"(\":\"\", \")\":\"\", \":\":\"\", \",\":\"\",\n",
        "                                         \"?\":\"\", \"*\":\"\", \"~\":\"\", \"\\\\\":\"\"}))\n",
        "                                        for s in hpList]\n",
        "hpListTrim = [s.replace(\"--\",\"\").replace(\"\\n\",\"\") for s in hpListTrim]\n",
        "print(hpListTrim[0])\n",
        "print(hpListTrim[10])\n",
        "print(hpListTrim[0], end=\"\")\n",
        "print(hpListTrim[10], end=\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMy5EaC0aMnM",
        "outputId": "553dc843-492a-47cf-8fb2-b3cbf61b71c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Harry Potter and the Sorcerers Stone\n",
            "because they just didnt hold with such nonsense\n",
            "Harry Potter and the Sorcerers Stonebecause they just didnt hold with such nonsense"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing the empty strings from the list\n",
        "print(len(hpListTrim))\n",
        "hpListTrim2 = list(filter(None, hpListTrim))\n",
        "print(len(hpListTrim2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8chQGD0asvi",
        "outputId": "f4ba83ad-842f-4e7d-9a63-36e239278732"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10702\n",
            "7640\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(hpListTrim2[1:4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRrjByXKbvBJ",
        "outputId": "6e9ec642-81fd-4c9d-dba1-157c6af963c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['CHAPTER ONE', 'THE BOY WHO LIVED', 'Mr and Mrs Dursley of number four Privet Drive were proud to say']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# processing lines into dictionary\n",
        "#from collections import Counter\n",
        "#print(hpListTrim2[10])\n",
        "#b = Counter(hpListTrim2[10])\n",
        "#print(b)\n",
        "def processLines(bookLines):\n",
        "  #print(bookLines)\n",
        "  wordDict = {}\n",
        "  # each sentence\n",
        "  for line in bookLines:\n",
        "    #print(line)\n",
        "    # each word\n",
        "    for word in line.lower().split():\n",
        "      #print(word)\n",
        "      if word in wordDict:\n",
        "        wordDict[word] += 1\n",
        "      else:\n",
        "        wordDict[word] = 1\n",
        "  return wordDict"
      ],
      "metadata": {
        "id": "PQyBMJ83f4FB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# turning a dictionary into a string of characters\n",
        "# First version just to get something working\n",
        "def dictToUniqueWordStringTest(bookDict):\n",
        "  uniqueWordString = \"\"\n",
        "  for key in bookDict.keys():\n",
        "    if uniqueWordString.find(key) < 0:\n",
        "      uniqueWordString += key\n",
        "  return uniqueWordString"
      ],
      "metadata": {
        "id": "gGPcWGgUmYgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# turning a dictionary into a string of characters\n",
        "# First version just to get something working\n",
        "def dictToUniqueWordString(bookDict):\n",
        "  uniqueWordString = \"\"\n",
        "  for key in bookDict.keys():\n",
        "    if len(uniqueWordString) == 0:\n",
        "      uniqueWordString += key\n",
        "    else:\n",
        "      place = 0\n",
        "      for char in key:\n",
        "        if place < 0:\n",
        "          uniqueWordString += char\n",
        "          print(\"added \\\"\",char,\"\\\" from \", key)\n",
        "        else:\n",
        "          place = uniqueWordString.find(char, place)\n",
        "          if place < 0:\n",
        "            uniqueWordString += char\n",
        "            print(\"added \\\"\",char,\"\\\" from \", key)\n",
        "          else:\n",
        "            place += 1\n",
        "  return uniqueWordString"
      ],
      "metadata": {
        "id": "rU6xrF13qIEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uniqueWordString = \"\"\n",
        "place = 0\n",
        "key = \"h\"\n",
        "print(type(key))\n",
        "uniqueWordString.find(key, place)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wi2otZEAxV11",
        "outputId": "d02c645d-74b5-4f7a-fd87-70f4abf38806"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'str'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the function (ver 1)\n",
        "# input: [\"Hello my name is\",\"My name is Ted\"]\n",
        "# expected result: {\"hello\": 1, \"my\":2,\"name\":2,\"is\":2,\"ted\":1}\n",
        "# expected result2: hellomynameisted\n",
        "\n",
        "inputString = [\"Hello my name is\",\"My name is Ted\"]\n",
        "print(inputString)\n",
        "result = processLines(inputString)\n",
        "print(result)\n",
        "result2 = dictToUniqueWordString(result)\n",
        "print(result2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ub85Gdvvnyh2",
        "outputId": "c86dd932-f398-48ea-9f16-40ab70f0100b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello my name is', 'My name is Ted']\n",
            "{'hello': 1, 'my': 2, 'name': 2, 'is': 2, 'ted': 1}\n",
            "added \" m \" from  my\n",
            "added \" y \" from  my\n",
            "added \" n \" from  name\n",
            "added \" a \" from  name\n",
            "added \" m \" from  name\n",
            "added \" e \" from  name\n",
            "added \" i \" from  is\n",
            "added \" s \" from  is\n",
            "added \" t \" from  ted\n",
            "added \" e \" from  ted\n",
            "added \" d \" from  ted\n",
            "hellomynameisted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the function (ver 1)\n",
        "# input: [\"hello we treat\",\"eat low\"]\n",
        "# expected result: {\"hello\": 1, \"we\":1,\"treat\":1,\"eat\":1,\"low\":1}\n",
        "# expected result2: hellowetreat\n",
        "\n",
        "inputString = [\"hello we treat\",\"eat low\"]\n",
        "print(inputString)\n",
        "result = processLines(inputString)\n",
        "print(result)\n",
        "result2 = dictToUniqueWordString(result)\n",
        "print(result2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sl7Zi9wQuuxs",
        "outputId": "dcd27ed7-653d-494b-ac7b-1addd21d1e49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hello we treat', 'eat low']\n",
            "{'hello': 1, 'we': 1, 'treat': 1, 'eat': 1, 'low': 1}\n",
            "added \" w \" from  we\n",
            "added \" e \" from  we\n",
            "added \" t \" from  treat\n",
            "added \" r \" from  treat\n",
            "added \" e \" from  treat\n",
            "added \" a \" from  treat\n",
            "added \" t \" from  treat\n",
            "hellowetreat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing with first 10 lines\n",
        "inputString = hpListTrim2[0:10]\n",
        "print(inputString)\n",
        "result = processLines(inputString)\n",
        "print(result)\n",
        "result2 = dictToUniqueWordString(result)\n",
        "print(result2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMWs2TIQmRzg",
        "outputId": "ab780790-a813-413b-bbd6-85339b211b23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Harry Potter and the Sorcerers Stone', 'CHAPTER ONE', 'THE BOY WHO LIVED', 'Mr and Mrs Dursley of number four Privet Drive were proud to say', 'that they were perfectly normal thank you very much They were the last', 'people youd expect to be involved in anything strange or mysterious', 'because they just didnt hold with such nonsense', 'Mr Dursley was the director of a firm called Grunnings which made', 'drills He was a big beefy man with hardly any neck although he did', 'have a very large mustache Mrs Dursley was thin and blonde and had']\n",
            "{'harry': 1, 'potter': 1, 'and': 4, 'the': 4, 'sorcerers': 1, 'stone': 1, 'chapter': 1, 'one': 1, 'boy': 1, 'who': 1, 'lived': 1, 'mr': 2, 'mrs': 2, 'dursley': 3, 'of': 2, 'number': 1, 'four': 1, 'privet': 1, 'drive': 1, 'were': 3, 'proud': 1, 'to': 2, 'say': 1, 'that': 1, 'they': 3, 'perfectly': 1, 'normal': 1, 'thank': 1, 'you': 1, 'very': 2, 'much': 1, 'last': 1, 'people': 1, 'youd': 1, 'expect': 1, 'be': 1, 'involved': 1, 'in': 1, 'anything': 1, 'strange': 1, 'or': 1, 'mysterious': 1, 'because': 1, 'just': 1, 'didnt': 1, 'hold': 1, 'with': 2, 'such': 1, 'nonsense': 1, 'was': 3, 'director': 1, 'a': 3, 'firm': 1, 'called': 1, 'grunnings': 1, 'which': 1, 'made': 1, 'drills': 1, 'he': 2, 'big': 1, 'beefy': 1, 'man': 1, 'hardly': 1, 'any': 1, 'neck': 1, 'although': 1, 'did': 1, 'have': 1, 'large': 1, 'mustache': 1, 'thin': 1, 'blonde': 1, 'had': 1}\n",
            "added \" p \" from  potter\n",
            "added \" o \" from  potter\n",
            "added \" t \" from  potter\n",
            "added \" t \" from  potter\n",
            "added \" e \" from  potter\n",
            "added \" r \" from  potter\n",
            "added \" n \" from  and\n",
            "added \" d \" from  and\n",
            "added \" h \" from  the\n",
            "added \" e \" from  the\n",
            "added \" s \" from  sorcerers\n",
            "added \" o \" from  sorcerers\n",
            "added \" r \" from  sorcerers\n",
            "added \" c \" from  sorcerers\n",
            "added \" e \" from  sorcerers\n",
            "added \" r \" from  sorcerers\n",
            "added \" e \" from  sorcerers\n",
            "added \" r \" from  sorcerers\n",
            "added \" s \" from  sorcerers\n",
            "added \" t \" from  stone\n",
            "added \" o \" from  stone\n",
            "added \" n \" from  stone\n",
            "added \" e \" from  stone\n",
            "added \" h \" from  chapter\n",
            "added \" a \" from  chapter\n",
            "added \" p \" from  chapter\n",
            "added \" t \" from  chapter\n",
            "added \" e \" from  chapter\n",
            "added \" r \" from  chapter\n",
            "added \" b \" from  boy\n",
            "added \" o \" from  boy\n",
            "added \" y \" from  boy\n",
            "added \" w \" from  who\n",
            "added \" h \" from  who\n",
            "added \" o \" from  who\n",
            "added \" l \" from  lived\n",
            "added \" i \" from  lived\n",
            "added \" v \" from  lived\n",
            "added \" e \" from  lived\n",
            "added \" d \" from  lived\n",
            "added \" m \" from  mr\n",
            "added \" r \" from  mr\n",
            "added \" s \" from  mrs\n",
            "added \" u \" from  dursley\n",
            "added \" r \" from  dursley\n",
            "added \" s \" from  dursley\n",
            "added \" l \" from  dursley\n",
            "added \" e \" from  dursley\n",
            "added \" y \" from  dursley\n",
            "added \" f \" from  of\n",
            "added \" m \" from  number\n",
            "added \" b \" from  number\n",
            "added \" e \" from  number\n",
            "added \" r \" from  number\n",
            "added \" o \" from  four\n",
            "added \" u \" from  four\n",
            "added \" r \" from  four\n",
            "added \" t \" from  privet\n",
            "added \" d \" from  proud\n",
            "added \" c \" from  perfectly\n",
            "added \" t \" from  perfectly\n",
            "added \" l \" from  perfectly\n",
            "added \" y \" from  perfectly\n",
            "added \" a \" from  normal\n",
            "added \" l \" from  normal\n",
            "added \" n \" from  thank\n",
            "added \" k \" from  thank\n",
            "added \" h \" from  much\n",
            "added \" s \" from  last\n",
            "added \" t \" from  last\n",
            "added \" x \" from  expect\n",
            "added \" p \" from  expect\n",
            "added \" e \" from  expect\n",
            "added \" c \" from  expect\n",
            "added \" t \" from  expect\n",
            "added \" v \" from  involved\n",
            "added \" o \" from  involved\n",
            "added \" l \" from  involved\n",
            "added \" v \" from  involved\n",
            "added \" e \" from  involved\n",
            "added \" d \" from  involved\n",
            "added \" i \" from  anything\n",
            "added \" n \" from  anything\n",
            "added \" g \" from  anything\n",
            "added \" e \" from  strange\n",
            "added \" r \" from  mysterious\n",
            "added \" i \" from  mysterious\n",
            "added \" o \" from  mysterious\n",
            "added \" u \" from  mysterious\n",
            "added \" s \" from  mysterious\n",
            "added \" e \" from  because\n",
            "added \" j \" from  just\n",
            "added \" u \" from  just\n",
            "added \" s \" from  just\n",
            "added \" t \" from  just\n",
            "added \" m \" from  firm\n",
            "added \" n \" from  grunnings\n",
            "added \" n \" from  grunnings\n",
            "added \" i \" from  grunnings\n",
            "added \" n \" from  grunnings\n",
            "added \" g \" from  grunnings\n",
            "added \" s \" from  grunnings\n",
            "added \" h \" from  although\n",
            "added \" e \" from  large\n",
            "harrypotterndhesorcererstonehapterboywholivedmrsursleyfmberourtdctlyalnkhstxpectvolvedingeriousejustmnningshe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing with entire book\n",
        "inputString = hpListTrim2\n",
        "#print(inputString)\n",
        "result = processLines(inputString)\n",
        "#print(result)\n",
        "result2 = dictToUniqueWordString(result)\n",
        "print(result2)\n",
        "print(len(result2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbxVvr-lwbFV",
        "outputId": "15d428be-4f86-4f64-e862-fb3301405491"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "added \" p \" from  potter\n",
            "added \" o \" from  potter\n",
            "added \" t \" from  potter\n",
            "added \" t \" from  potter\n",
            "added \" e \" from  potter\n",
            "added \" r \" from  potter\n",
            "added \" n \" from  and\n",
            "added \" d \" from  and\n",
            "added \" h \" from  the\n",
            "added \" e \" from  the\n",
            "added \" s \" from  sorcerers\n",
            "added \" o \" from  sorcerers\n",
            "added \" r \" from  sorcerers\n",
            "added \" c \" from  sorcerers\n",
            "added \" e \" from  sorcerers\n",
            "added \" r \" from  sorcerers\n",
            "added \" e \" from  sorcerers\n",
            "added \" r \" from  sorcerers\n",
            "added \" s \" from  sorcerers\n",
            "added \" t \" from  stone\n",
            "added \" o \" from  stone\n",
            "added \" n \" from  stone\n",
            "added \" e \" from  stone\n",
            "added \" h \" from  chapter\n",
            "added \" a \" from  chapter\n",
            "added \" p \" from  chapter\n",
            "added \" t \" from  chapter\n",
            "added \" e \" from  chapter\n",
            "added \" r \" from  chapter\n",
            "added \" b \" from  boy\n",
            "added \" o \" from  boy\n",
            "added \" y \" from  boy\n",
            "added \" w \" from  who\n",
            "added \" h \" from  who\n",
            "added \" o \" from  who\n",
            "added \" l \" from  lived\n",
            "added \" i \" from  lived\n",
            "added \" v \" from  lived\n",
            "added \" e \" from  lived\n",
            "added \" d \" from  lived\n",
            "added \" m \" from  mr\n",
            "added \" r \" from  mr\n",
            "added \" s \" from  mrs\n",
            "added \" u \" from  dursley\n",
            "added \" r \" from  dursley\n",
            "added \" s \" from  dursley\n",
            "added \" l \" from  dursley\n",
            "added \" e \" from  dursley\n",
            "added \" y \" from  dursley\n",
            "added \" f \" from  of\n",
            "added \" m \" from  number\n",
            "added \" b \" from  number\n",
            "added \" e \" from  number\n",
            "added \" r \" from  number\n",
            "added \" o \" from  four\n",
            "added \" u \" from  four\n",
            "added \" r \" from  four\n",
            "added \" t \" from  privet\n",
            "added \" d \" from  proud\n",
            "added \" c \" from  perfectly\n",
            "added \" t \" from  perfectly\n",
            "added \" l \" from  perfectly\n",
            "added \" y \" from  perfectly\n",
            "added \" a \" from  normal\n",
            "added \" l \" from  normal\n",
            "added \" n \" from  thank\n",
            "added \" k \" from  thank\n",
            "added \" h \" from  much\n",
            "added \" s \" from  last\n",
            "added \" t \" from  last\n",
            "added \" x \" from  expect\n",
            "added \" p \" from  expect\n",
            "added \" e \" from  expect\n",
            "added \" c \" from  expect\n",
            "added \" t \" from  expect\n",
            "added \" v \" from  involved\n",
            "added \" o \" from  involved\n",
            "added \" l \" from  involved\n",
            "added \" v \" from  involved\n",
            "added \" e \" from  involved\n",
            "added \" d \" from  involved\n",
            "added \" i \" from  anything\n",
            "added \" n \" from  anything\n",
            "added \" g \" from  anything\n",
            "added \" e \" from  strange\n",
            "added \" r \" from  mysterious\n",
            "added \" i \" from  mysterious\n",
            "added \" o \" from  mysterious\n",
            "added \" u \" from  mysterious\n",
            "added \" s \" from  mysterious\n",
            "added \" e \" from  because\n",
            "added \" j \" from  just\n",
            "added \" u \" from  just\n",
            "added \" s \" from  just\n",
            "added \" t \" from  just\n",
            "added \" m \" from  firm\n",
            "added \" n \" from  grunnings\n",
            "added \" n \" from  grunnings\n",
            "added \" i \" from  grunnings\n",
            "added \" n \" from  grunnings\n",
            "added \" g \" from  grunnings\n",
            "added \" s \" from  grunnings\n",
            "added \" h \" from  although\n",
            "added \" e \" from  large\n",
            "added \" a \" from  garden\n",
            "added \" r \" from  garden\n",
            "added \" d \" from  garden\n",
            "added \" e \" from  garden\n",
            "added \" n \" from  garden\n",
            "added \" b \" from  neighbors\n",
            "added \" o \" from  neighbors\n",
            "added \" r \" from  neighbors\n",
            "added \" s \" from  neighbors\n",
            "added \" y \" from  dudley\n",
            "added \" t \" from  greatest\n",
            "added \" e \" from  greatest\n",
            "added \" s \" from  greatest\n",
            "added \" t \" from  greatest\n",
            "added \" d \" from  good-for-nothing\n",
            "added \" - \" from  good-for-nothing\n",
            "added \" f \" from  good-for-nothing\n",
            "added \" o \" from  good-for-nothing\n",
            "added \" r \" from  good-for-nothing\n",
            "added \" - \" from  good-for-nothing\n",
            "added \" n \" from  good-for-nothing\n",
            "added \" o \" from  good-for-nothing\n",
            "added \" t \" from  good-for-nothing\n",
            "added \" h \" from  good-for-nothing\n",
            "added \" i \" from  good-for-nothing\n",
            "added \" n \" from  good-for-nothing\n",
            "added \" g \" from  good-for-nothing\n",
            "added \" l \" from  undursleyish\n",
            "added \" e \" from  undursleyish\n",
            "added \" y \" from  undursleyish\n",
            "added \" i \" from  undursleyish\n",
            "added \" s \" from  undursleyish\n",
            "added \" h \" from  undursleyish\n",
            "added \" w \" from  knew\n",
            "added \" p \" from  keeping\n",
            "added \" i \" from  keeping\n",
            "added \" n \" from  keeping\n",
            "added \" g \" from  keeping\n",
            "added \" x \" from  mixing\n",
            "added \" i \" from  mixing\n",
            "added \" n \" from  mixing\n",
            "added \" g \" from  mixing\n",
            "added \" e \" from  gossiped\n",
            "added \" d \" from  gossiped\n",
            "added \" c \" from  briefcase\n",
            "added \" a \" from  briefcase\n",
            "added \" s \" from  briefcase\n",
            "added \" e \" from  briefcase\n",
            "added \" b \" from  good-bye\n",
            "added \" y \" from  good-bye\n",
            "added \" e \" from  good-bye\n",
            "added \" k \" from  backed\n",
            "added \" e \" from  backed\n",
            "added \" d \" from  backed\n",
            "added \" z \" from  realize\n",
            "added \" e \" from  realize\n",
            "added \" i \" from  looking\n",
            "added \" n \" from  looking\n",
            "added \" g \" from  looking\n",
            "added \" v \" from  gave\n",
            "added \" e \" from  gave\n",
            "added \" t \" from  except\n",
            "added \" m \" from  jam\n",
            "added \" u \" from  getups\n",
            "added \" p \" from  getups\n",
            "added \" s \" from  getups\n",
            "added \" o \" from  supposed\n",
            "added \" s \" from  supposed\n",
            "added \" e \" from  supposed\n",
            "added \" d \" from  supposed\n",
            "added \" n \" from  fashion\n",
            "added \" q \" from  quite\n",
            "added \" u \" from  quite\n",
            "added \" i \" from  quite\n",
            "added \" t \" from  quite\n",
            "added \" e \" from  quite\n",
            "added \" r \" from  emerald-green\n",
            "added \" e \" from  emerald-green\n",
            "added \" e \" from  emerald-green\n",
            "added \" n \" from  emerald-green\n",
            "added \" t \" from  different\n",
            "added \" a \" from  squeaky\n",
            "added \" k \" from  squeaky\n",
            "added \" y \" from  squeaky\n",
            "added \" w \" from  you-know-who\n",
            "added \" - \" from  you-know-who\n",
            "added \" w \" from  you-know-who\n",
            "added \" h \" from  you-know-who\n",
            "added \" o \" from  you-know-who\n",
            "added \" r \" from  behavior\n",
            "added \" l \" from  finally\n",
            "added \" y \" from  finally\n",
            "added \" c \" from  bird-watchers\n",
            "added \" h \" from  bird-watchers\n",
            "added \" e \" from  bird-watchers\n",
            "added \" r \" from  bird-watchers\n",
            "added \" s \" from  bird-watchers\n",
            "added \" e \" from  everywhere\n",
            "added \" g \" from  behaving\n",
            "added \" f \" from  mcguffin\n",
            "added \" i \" from  mcguffin\n",
            "added \" n \" from  mcguffin\n",
            "added \" k \" from  funny-looking\n",
            "added \" i \" from  funny-looking\n",
            "added \" n \" from  funny-looking\n",
            "added \" g \" from  funny-looking\n",
            "added \" l \" from  quickly\n",
            "added \" y \" from  quickly\n",
            "added \" v \" from  quiver\n",
            "added \" e \" from  quiver\n",
            "added \" r \" from  quiver\n",
            "added \" d \" from  high-heeled\n",
            "added \" o \" from  unwelcome\n",
            "added \" m \" from  unwelcome\n",
            "added \" e \" from  unwelcome\n",
            "added \" t \" from  exasperated\n",
            "added \" e \" from  exasperated\n",
            "added \" d \" from  exasperated\n",
            "added \" s \" from  mcgonagalls\n",
            "added \" l \" from  glumly\n",
            "added \" y \" from  glumly\n",
            "added \" f \" from  handkerchief\n",
            "added \" a \" from  jet-black\n",
            "added \" c \" from  jet-black\n",
            "added \" k \" from  jet-black\n",
            "added \" r \" from  s-s-sorry\n",
            "added \" r \" from  s-s-sorry\n",
            "added \" y \" from  s-s-sorry\n",
            "added \" n \" from  c-c-cant\n",
            "added \" t \" from  c-c-cant\n",
            "added \" o \" from  different-colored\n",
            "added \" r \" from  different-colored\n",
            "added \" e \" from  different-colored\n",
            "added \" d \" from  different-colored\n",
            "added \" i \" from  question\n",
            "added \" o \" from  question\n",
            "added \" n \" from  question\n",
            "added \" s \" from  questions\n",
            "added \" p \" from  unwrap\n",
            "added \" m \" from  whats-her-name\n",
            "added \" e \" from  whats-her-name\n",
            "added \" g \" from  cabbage-smelling\n",
            "added \" b \" from  remarkably\n",
            "added \" l \" from  remarkably\n",
            "added \" y \" from  remarkably\n",
            "added \" o \" from  knickerbocker\n",
            "added \" c \" from  knickerbocker\n",
            "added \" k \" from  knickerbocker\n",
            "added \" e \" from  knickerbocker\n",
            "added \" r \" from  knickerbocker\n",
            "added \" u \" from  man-crushing\n",
            "added \" s \" from  man-crushing\n",
            "added \" h \" from  man-crushing\n",
            "added \" i \" from  man-crushing\n",
            "added \" n \" from  man-crushing\n",
            "added \" g \" from  man-crushing\n",
            "added \" z \" from  squeeze\n",
            "added \" e \" from  squeeze\n",
            "added \" p \" from  grown-up\n",
            "added \" 4 \" from  4\n",
            "added \" t \" from  p-p-petunia\n",
            "added \" u \" from  p-p-petunia\n",
            "added \" n \" from  p-p-petunia\n",
            "added \" i \" from  p-p-petunia\n",
            "added \" a \" from  p-p-petunia\n",
            "added \" d \" from  squeezed\n",
            "added \" y \" from  squashy\n",
            "added \" n \" from  whizzing\n",
            "added \" g \" from  whizzing\n",
            "added \" - \" from  gloomy-looking\n",
            "added \" l \" from  gloomy-looking\n",
            "added \" o \" from  gloomy-looking\n",
            "added \" o \" from  gloomy-looking\n",
            "added \" k \" from  gloomy-looking\n",
            "added \" i \" from  gloomy-looking\n",
            "added \" n \" from  gloomy-looking\n",
            "added \" g \" from  gloomy-looking\n",
            "added \" 1 \" from  17\n",
            "added \" 7 \" from  17\n",
            "added \" l \" from  gleefully\n",
            "added \" y \" from  gleefully\n",
            "added \" r \" from  hut-on-the-rock\n",
            "added \" o \" from  hut-on-the-rock\n",
            "added \" c \" from  hut-on-the-rock\n",
            "added \" k \" from  hut-on-the-rock\n",
            "added \" 3 \" from  31\n",
            "added \" 1 \" from  31\n",
            "added \" 0 \" from  0\n",
            "added \" w \" from  canary-yellow\n",
            "added \" 2 \" from  2\n",
            "added \" t \" from  p-p-potter\n",
            "added \" e \" from  p-p-potter\n",
            "added \" r \" from  p-p-potter\n",
            "added \" h \" from  quidditch\n",
            "added \" g \" from  jelly-legs\n",
            "added \" s \" from  jelly-legs\n",
            "added \" b \" from  jewel-bright\n",
            "added \" r \" from  jewel-bright\n",
            "added \" i \" from  jewel-bright\n",
            "added \" g \" from  jewel-bright\n",
            "added \" h \" from  jewel-bright\n",
            "added \" t \" from  jewel-bright\n",
            "added \" 8 \" from  382\n",
            "added \" 2 \" from  382\n",
            "added \" a \" from  thirteen-and-a-half\n",
            "added \" l \" from  thirteen-and-a-half\n",
            "added \" f \" from  thirteen-and-a-half\n",
            "added \" e \" from  who-must-not-be-named\n",
            "added \" - \" from  who-must-not-be-named\n",
            "added \" n \" from  who-must-not-be-named\n",
            "added \" a \" from  who-must-not-be-named\n",
            "added \" m \" from  who-must-not-be-named\n",
            "added \" e \" from  who-must-not-be-named\n",
            "added \" d \" from  who-must-not-be-named\n",
            "added \" 9 \" from  1945\n",
            "added \" 4 \" from  1945\n",
            "added \" 5 \" from  1945\n",
            "added \" t \" from  quick-witted\n",
            "added \" e \" from  quick-witted\n",
            "added \" d \" from  quick-witted\n",
            "added \" l \" from  finch-fletchley\n",
            "added \" e \" from  finch-fletchley\n",
            "added \" t \" from  finch-fletchley\n",
            "added \" c \" from  finch-fletchley\n",
            "added \" h \" from  finch-fletchley\n",
            "added \" l \" from  finch-fletchley\n",
            "added \" e \" from  finch-fletchley\n",
            "added \" y \" from  finch-fletchley\n",
            "added \" o \" from  out-of-bounds\n",
            "added \" u \" from  out-of-bounds\n",
            "added \" n \" from  out-of-bounds\n",
            "added \" d \" from  out-of-bounds\n",
            "added \" s \" from  out-of-bounds\n",
            "added \" t \" from  puzzlement\n",
            "added \" g \" from  zigzagging\n",
            "added \" 7 \" from  1473\n",
            "added \" 3 \" from  1473\n",
            "added \" p \" from  loop-the-loops\n",
            "added \" s \" from  loop-the-loops\n",
            "added \" w \" from  grow-your-own-warts\n",
            "added \" n \" from  grow-your-own-warts\n",
            "added \" - \" from  grow-your-own-warts\n",
            "added \" w \" from  grow-your-own-warts\n",
            "added \" a \" from  grow-your-own-warts\n",
            "added \" r \" from  grow-your-own-warts\n",
            "added \" t \" from  grow-your-own-warts\n",
            "added \" s \" from  grow-your-own-warts\n",
            "added \" g \" from  aaaaaaaaaargh\n",
            "added \" h \" from  aaaaaaaaaargh\n",
            "added \" x \" from  snuffbox\n",
            "added \" 6 \" from  1637\n",
            "added \" 3 \" from  1637\n",
            "added \" 7 \" from  1637\n",
            "added \" 0 \" from  90\n",
            "harrypotterndhesorcererstonehapterboywholivedmrsursleyfmberourtdctlyalnkhstxpectvolvedingeriousejustmnningsheardenborsytestd-for-nothingleyishwpingxingedcasebyekedzeingvetmupsosednquitereentakyw-whorlychersegfinkinglyverdometedslyfackrryntoredionspmegblyockerushingzep4tuniadyng-looking17lyrock310w2terhgsbright82alfe-named945tedletchleyoundstg73pswn-wartsghx6370\n",
            "363\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "beforehhh = result2[0:result2.find(\"shhhh\")]\n",
        "print(beforehhh)\n",
        "inputString = \"shhhh\"\n",
        "place = 0\n",
        "for char in inputString:\n",
        "  place = beforehhh.find(char,place)\n",
        "  print(\"char:\",char,\"\\nloc:\",place)\n",
        "  place += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FH4QgB6G2Ib3",
        "outputId": "1c324f3b-f5d8-4087-8394-87fd714b63ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "harrypotterndhesorcererstonehapterboywholivedmrsursleyfmberourtdctlyalnkhstxpectvolvedingeriousejustmnningsheardenborsytestd-for-nothingleyishwpingxingedcasebyekedzeingvetmupsosednquitereentakyw-whorlychersegfinkinglyverdometedslyfackrryntoredionspmegblyockerushingzep4tuniadyng-looking17lyrock310w2terhgsbright82alfe-named945tedletchleyoundstg73pswn-wartsghx637\n",
            "char: s \n",
            "loc: 15\n",
            "char: h \n",
            "loc: 28\n",
            "char: h \n",
            "loc: 38\n",
            "char: h \n",
            "loc: 72\n",
            "char: h \n",
            "loc: 107\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function to test the location of words\n",
        "def testWordPlacement(uniqueWordString, key):\n",
        "  place = 0\n",
        "  print(\"length before:\",len(uniqueWordString))\n",
        "  for char in key:\n",
        "    if place == -1:\n",
        "      print(\"place:\",place)\n",
        "      print(\"appending character because end\")\n",
        "      uniqueWordString += char\n",
        "    else:\n",
        "      print(\"searching for:\",char)\n",
        "      place = uniqueWordString.find(char, place)\n",
        "      if place < 0:\n",
        "        print(\"char not in list\")\n",
        "        uniqueWordString += char\n",
        "      else:\n",
        "        print(\"char in list at:\",place)\n",
        "        place += 1\n",
        "  print(\"length after:\",len(uniqueWordString))"
      ],
      "metadata": {
        "id": "F7HyuAeF4joV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uniqueWordString = result2\n",
        "key = \"1075\"\n",
        "testWordPlacement(uniqueWordString,key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-YzO3tf-e-J",
        "outputId": "2598452b-2c32-461e-e633-b5521fa39adf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length before: 363\n",
            "searching for: 1\n",
            "char in list at: 286\n",
            "searching for: 0\n",
            "char in list at: 296\n",
            "searching for: 7\n",
            "char in list at: 344\n",
            "searching for: 5\n",
            "char not in list\n",
            "length after: 364\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# List comprehension\n",
        "#a = [i for i in range(10)]\n",
        "\n",
        "\n",
        "#List filtering\n",
        "#a = [1, 2, 3, 6, 7, 8, 4]\n",
        "# Keep only numbers less than or equal to 5\n",
        "\n",
        "#a = list(filter(lambda x: x <= 5, a))\n",
        "#print(a)"
      ],
      "metadata": {
        "id": "mKzGMfqTZH0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(result2)"
      ],
      "metadata": {
        "id": "MLGyjUxVERdW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f0683b5-1880-4221-9b80-80a5f777a1af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "363"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    }
  ]
}